// Code generated by SlParser.
package test

import (
	"fmt"

	"github.com/PlayerR9/go-commons/errors"
	"github.com/PlayerR9/grammar/ast"
	"github.com/PlayerR9/grammar/lexer"
	"github.com/PlayerR9/grammar/parser"
)

// NodeType represents the type of a node in the AST tree.
type NodeType int

const (
	SourceNode NodeType = iota
	// Add here your custom node types.
)

// String implements the NodeTyper interface.
func (t NodeType) String() string {
	return [...]string{
		"Source",
		// Add here your custom node names.
	}[t]
}

// DebugSetting represents the debug settings.
type DebugSetting int

const (
	// ShowNone is the debug setting that does not show any debug information.
	ShowNone DebugSetting = 0

	// ShowLex is the debug setting that shows the tokens after lexing.
	ShowLex  DebugSetting = 1

	// ShowTree is the debug setting that shows the raw parsed tree after parsing.
	ShowTree DebugSetting = 2

	// ShowAst is the debug setting that shows the AST tree after the AST generation.
	ShowAst  DebugSetting = 4

	// ShowData is the debug setting that shows the data read from the input file.
	ShowData DebugSetting = 8

	// ShowAll is the debug setting that shows all debug information.
	ShowAll DebugSetting = ShowLex | ShowTree | ShowAst | ShowData
)

// Parse parses the given data and returns the AST tree.
//
// Parameters:
//   - data: The data to parse.
//   - debug: The debug setting.
//
// Returns:
//   - *ast.Node[NodeType]: The AST tree.
//   - error: An error if the parsing failed.
func Parse(data []byte, debug DebugSetting) (*ast.Node[NodeType], error) {
	if len(data) == 0 {
		return nil, errors.NewErrInvalidParameter("data", errors.NewErrEmpty(data))
	}

	if debug&ShowData != 0 {
		fmt.Println("Debug option show_data is enabled, printing data:")
		fmt.Println(string(data))
		fmt.Println()
	}

	tokens, err := internal_lexer.FullLex(data)

	if debug&ShowLex != 0 {
		fmt.Println("Debug option show_lex is enabled, printing tokens:")
		for _, token := range tokens {
			fmt.Println("\t-", token.String())
		}
		fmt.Println()
	}

	if err != nil {
		// DEBUG: Print tokens:
		fmt.Println(string(lexer.PrintSyntaxError(data, tokens)))
		fmt.Println()

		return nil, fmt.Errorf("error while lexing: %w", err)
	}

	forest, err := parser.FullParse(internal_parser, tokens)

	if debug&ShowTree != 0 {
		fmt.Println("Debug option show_tree is enabled, printing forest:")

		for _, tree := range forest {
			fmt.Println(tree.String())
			fmt.Println()
		}

		fmt.Println()
	}

	if err != nil {
		return nil, fmt.Errorf("error while parsing: %w", err)
	} else if len(forest) != 1 {
		return nil, fmt.Errorf("expected 1 tree, got %d trees instead", len(forest))
	}

	nodes, err := ast_builder.Apply(forest[0])

	if debug&ShowAst != 0 {
		fmt.Println("Debug option show_ast is enabled, printing nodes:")

		for _, node := range nodes {
			fmt.Println(ast.PrintAst(node))
			fmt.Println()
		}

		fmt.Println()
	}

	if err != nil {
		return nil, fmt.Errorf("error while converting to AST: %w", err)
	} else if len(nodes) != 1 {
		return nil, fmt.Errorf("expected 1 node, got %d nodes instead", len(nodes))
	}

	return nodes[0], nil
}

var (
	// ast_builder is the AST builder of the parser.
	ast_builder *ast.Make[*ast.Node[NodeType], token_type]
)

func init() {
	ast_builder = ast.NewMake[*ast.Node[NodeType], token_type]()

	// Initialize the parts builder. (if needed)
	// parts := ast.NewPartsBuilder[*ast.Node[NodeType]]()

	// Here's an example of how to use the parts builder:
	/*
	parts.Reset() // Reset any previous parts.

	// 1st part: Extract the necessary children from the current token.
	// As an example, this part extracts the source code from the token according to the following rule:
	// 	Source = Source1 EOF .

	parts.Add(func(a *ast.Result[*ast.Node[NodeType]], prev any) (any, error) {
		root := prev.(*gr.Token[token_type])

		a.SetNode(ast.NewNode(SourceNode, ""))

		children, err := ast.ExtractChildren(root)
		if err != nil {
			return nil, err
		}

		if len(children) != 2 {
			return nil, fmt.Errorf("expected 2 children, got %d children instead", len(children))
		}

		return children[0], nil
	})

	// sub_part is an helper function for the second part, that is, a function that applies the
	// ast_builder on the first token. This is because the rule is:
	// 	Source1 = Rule [ Source1 ] .
	sub_part := func(children []*gr.Token[token_type]) ([]*ast.Node[NodeType], error) {
		nodes, err := ast_builder.ApplyToken(children[0])
		if err != nil {
			return nodes, err
		}

		return nodes, nil
	}

	// 2nd part: Left-recursive grammar rule.
	parts.Add(func(a *ast.Result[*ast.Node[NodeType]], prev any) (any, error) {
		child := prev.(*gr.Token[token_type])

		sub_nodes, err := ast.LeftRecursive(child, ntk_Source1, sub_part)
		a_nodes := make([]ast.Noder, 0, len(sub_nodes))

		for _, node := range sub_nodes {
			a_nodes = append(a_nodes, node)
		}

		a.AppendChildren(a_nodes)

		if err != nil {
			return nil, err
		}

		return nil, nil
	})

	ast_builder.AddEntry(ntk_Source, parts.Build()) // Add the grammar rule to the AST builder.
	*/
}
