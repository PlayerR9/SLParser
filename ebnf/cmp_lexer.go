// Code generated by SlParser.
package ebnf

import (
	"fmt"
	"io"
	"unicode"

	"github.com/PlayerR9/grammar/grammar"
	"github.com/PlayerR9/grammar/lexing"
)

var (
	// matcher is the matcher of the grammar.
	matcher *lexing.Matcher[token_type]

	lex_whitespace lexing.LexFunc
	lex_digit      lexing.LexFunc
	lex_lowercase  lexing.LexFunc
	lex_newlines   lexing.LexFunc

	frag_uppercases lexing.LexFunc
	frag_lowercases lexing.LexFunc
)

func init() {
	matcher = lexing.NewMatcher[token_type]()

	// Add here your custom matcher rules.

	_ = matcher.AddToMatch(ttk_Dot, ".")
	_ = matcher.AddToMatch(ttk_OpParen, "(")
	_ = matcher.AddToMatch(ttk_ClParen, ")")
	_ = matcher.AddToMatch(ttk_Pipe, "|")
	_ = matcher.AddToMatch(ttk_Equal, "=")
	_ = matcher.AddToMatch(ttk_UppercaseId, "EOF")

	lex_whitespace = func(scanner io.RuneScanner) ([]rune, error) {
		// [ \t]+

		c, _, err := scanner.ReadRune()
		if err != nil {
			return nil, err
		}

		if c != ' ' && c != '\t' {
			_ = scanner.UnreadRune()

			return nil, lexing.Done
		}

		return []rune{c}, nil
	}

	lex_digit = func(scanner io.RuneScanner) ([]rune, error) {
		// [0-9]+

		c, _, err := scanner.ReadRune()
		if err != nil {
			return nil, err
		}

		if !unicode.IsDigit(c) {
			_ = scanner.UnreadRune()

			return nil, lexing.Done
		}

		return []rune{c}, nil
	}

	lex_newlines = func(scanner io.RuneScanner) ([]rune, error) {
		// ([\r]?[\n])+

		c1, _, err := scanner.ReadRune()
		if err != nil {
			return nil, err
		}

		if c1 == '\n' {
			return []rune{c1}, nil
		}

		if c1 != '\r' {
			_ = scanner.UnreadRune()

			return nil, lexing.Done
		}

		c2, _, err := scanner.ReadRune()
		if err == io.EOF {
			return nil, lexing.NewErrUnexpectedRune(&c1, nil, '\n')
		} else if err != nil {
			return nil, err
		}

		if c2 != '\n' {
			_ = scanner.UnreadRune()

			return nil, lexing.NewErrUnexpectedRune(&c1, &c2, '\n')
		}

		return []rune{c2}, nil
	}

	lex_lowercase = func(scanner io.RuneScanner) ([]rune, error) {
		// [a-z]+

		c, _, err := scanner.ReadRune()
		if err != nil {
			return nil, err
		}

		if !unicode.IsLower(c) {
			_ = scanner.UnreadRune()

			return nil, lexing.Done
		}

		return []rune{c}, nil
	}

	frag_uppercases = func(scanner io.RuneScanner) ([]rune, error) {
		// ([A-Z] | [A-Z] lowercase)+

		c, _, err := scanner.ReadRune()
		if err != nil {
			return nil, err
		}

		if !unicode.IsUpper(c) {
			_ = scanner.UnreadRune()

			return nil, lexing.Done
		}

		chars, err := lexing.RightLex(scanner, lex_lowercase)
		if err != nil {
			return []rune{c}, nil
		}

		return append([]rune{c}, chars...), nil
	}

	frag_lowercases = func(scanner io.RuneScanner) ([]rune, error) {
		// (lowercase | lowercase [_])+

		chars, err := lexing.RightLex(scanner, lex_lowercase)
		if err != nil {
			return nil, err
		}

		c, _, err := scanner.ReadRune()
		if err != nil {
			return chars, err
		}

		if c != '_' {
			_ = scanner.UnreadRune()

			return chars, lexing.Done
		}

		chars = append(chars, c)

		return chars, nil
	}
}

var (
	// internal_lexer is the lexer of the grammar.
	internal_lexer *lexing.Lexer[token_type]
)

func init() {
	lex_one := func(l *lexing.Lexer[token_type]) (*grammar.Token[token_type], error) {
		// Lex here anything that matcher doesn't handle...

		at := l.Pos()

		chars, err := lexing.RightLex(l, lex_whitespace)
		if err != nil {
			return nil, err
		}

		if len(chars) != 0 {
			return nil, nil
		}

		chars, err = lexing.RightLex(l, lex_newlines)
		if err != nil {
			return nil, err
		}

		if len(chars) != 0 {
			return grammar.NewToken(ttk_Newline, "\n", at, nil), nil
		}

		chars, err = lexing.RightLex(l, frag_uppercases)
		if err != nil {
			return nil, err
		}

		if len(chars) != 0 {
			// do digits

			digit, err := lexing.RightLex(l, lex_digit)
			if err != nil {
				return nil, err
			}

			chars = append(chars, digit...)

			return grammar.NewToken(ttk_UppercaseId, string(chars), at, nil), nil
		}

		chars, err = lexing.RightLex(l, frag_lowercases)
		if err != nil {
			return nil, err
		}

		if len(chars) != 0 {
			// do digits

			digit, err := lexing.RightLex(l, lex_digit)
			if err != nil {
				return nil, err
			}

			chars = append(chars, digit...)

			return grammar.NewToken(ttk_LowercaseId, string(chars), at, nil), nil
		}

		return nil, fmt.Errorf("no match found at %d", at)
	}

	internal_lexer = lexing.NewLexer(lex_one, matcher)
}
