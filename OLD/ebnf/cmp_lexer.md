// Code generated by SlParser.
package ebnf

import (
	"io"
	"unicode"

	dbg "github.com/PlayerR9/go-debug/assert"
	"github.com/PlayerR9/grammar/grammar"
	"github.com/PlayerR9/grammar/lexer"
)

var (
	// [0-9]+
	cat_digits lexer.LexFunc

	// [A-Z]+
	cat_uppercases lexer.LexFunc

	// [a-z]+
	cat_must_lowercases lexer.LexFunc

	// [a-z]+
	cat_lowercases lexer.LexFunc

	lex_uppercase lexer.LexFunc
	lex_lowercase lexer.LexFunc
)

func init() {
	cat_digits = lexer.MakeCategoryLexer(unicode.IsDigit, lexer.MustLexMany)
	cat_uppercases = lexer.MakeCategoryLexer(unicode.IsUpper, lexer.MustLexMany)
	cat_lowercases = lexer.MakeCategoryLexer(unicode.IsLower, lexer.MustLexMany)
	cat_must_lowercases = lexer.MakeCategoryLexer(unicode.IsLower, lexer.MustLexMany)

	lex_lowercase = func(scanner io.RuneScanner) ([]rune, error) {
		// [a-z]+([A-Z][a-z]*)*

		chars, err := lexer.RightLex(scanner, cat_must_lowercases)
		if err != nil {
			return chars, err
		}

		for {
			c, _, err := scanner.ReadRune()
			if err != nil {
				if err != io.EOF {
					return chars, err
				}

				break
			}

			if !unicode.IsUpper(c) {
				err := scanner.UnreadRune()
				dbg.AssertErr(err, "scanner.UnreadRune()")

				break
			}

			chars = append(chars, c)

			tmp, err := lexer.RightLex(scanner, cat_lowercases)
			chars = append(chars, tmp...)

			if err != nil {
				return chars, err
			}
		}

		return chars, nil
	}

	lex_uppercase = func(scanner io.RuneScanner) ([]rune, error) {
		// uppercases ([_] uppercases)*

		var chars []rune

		for {
			tmp, err := lexer.RightLex(scanner, cat_uppercases)
			chars = append(chars, tmp...)

			if err != nil {
				return chars, lexer.NoMatch
			}

			c, _, err := scanner.ReadRune()
			if err != nil {
				if err != io.EOF {
					return chars, err
				}

				break
			}

			if c != '_' {
				err := scanner.UnreadRune()
				dbg.AssertErr(err, "scanner.UnreadRune()")

				break
			}

			chars = append(chars, c)
		}

		if len(chars) == 0 {
			return chars, lexer.NoMatch
		}

		return chars, nil
	}
}

var (
	// internal_lexer is the lexer of the grammar.
	internal_lexer lexer.Lexer[token_type]
)

func init() {
	lex_one := func(l *lexer.Lexer[token_type]) (*grammar.Token[token_type], error) {
		// Lex here anything that matcher doesn't handle...

		at := l.Pos()

		/* chars, err := lexing.RightLex(l, lex_whitespace)
		if err != nil {
			return nil, err
		}

		if len(chars) != 0 {
			return nil, nil
		}

		chars, err = lexing.RightLex(l, lex_newlines)
		if err != nil {
			return nil, err
		}

		if len(chars) != 0 {
			return nil, nil
		} */

		chars, err := lexer.RightLex(l, lex_uppercase)
		if err == nil {
			digits, err := lexer.RightLex(l, cat_digits)
			if err != nil && err != lexer.NoMatch {
				return nil, err
			}

			chars = append(chars, digits...)

			return grammar.NewToken(ttk_UppercaseId, string(chars), at, nil), nil
		} else if err != lexer.NoMatch {
			return nil, err
		}

		chars, err = lexer.RightLex(l, lex_lowercase)
		if err == nil {
			digits, err := lexer.RightLex(l, cat_digits)
			if err != nil && err != lexer.NoMatch {
				return nil, err
			}

			chars = append(chars, digits...)

			return grammar.NewToken(ttk_LowercaseId, string(chars), at, nil), nil
		} else if err != lexer.NoMatch {
			return nil, err
		}

		return nil, lexer.NoMatch
	}

	internal_lexer.WithLexFunc(lex_one)

	// Add here your custom matcher rules.

	_ = internal_lexer.AddToMatch(ttk_Semicolon, ";")
	_ = internal_lexer.AddToMatch(ttk_OpParen, "(")
	_ = internal_lexer.AddToMatch(ttk_ClParen, ")")
	_ = internal_lexer.AddToMatch(ttk_Pipe, "|")
	_ = internal_lexer.AddToMatch(ttk_Colon, ":")
	_ = internal_lexer.AddToMatch(ttk_UppercaseId, "EOF")
	_ = internal_lexer.AddToSkipRule(" ", "\t")
	_ = internal_lexer.AddToSkipRule("\r\n", "\n")
}
